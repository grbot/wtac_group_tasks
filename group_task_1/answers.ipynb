{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Group Task 1 Answers\n",
    "\n",
    "Given an RNA-Seq experiment with a knocked out gene, you were asked to answer the following questions:\n",
    "\n",
    "  * What influence does it have?   \n",
    "  * What is the name of the knock out gene?\n",
    "  * How did you determine those?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "You were given the following files in order to conduct the analysis:\n",
    "\n",
    "  * Wild type sample reads in FASTQ format  \n",
    "    `WT[replicate]_[1|2].fastq.gz`  \n",
    "\n",
    "\n",
    "  * Knockout sample reads in FASTQ format  \n",
    "    `KO[replicate]_[1|2].fastq.gz`\n",
    "  \n",
    "  \n",
    "  * _P. berghi_ genome in FASTA format  \n",
    "    `PbANKA_v3.fasta`\n",
    "    \n",
    "    \n",
    "  * _P. berghi_ transcripts in FASTA format  \n",
    "    `Pb.CDS.fasta`\n",
    "    \n",
    "\n",
    "  * _P. berghi_ annotations in GFF format  \n",
    "    `PbANKA_v3.gff3.gz`\n",
    "    \n",
    "    \n",
    "  * _P. berghi_ gene descriptions in TSV format  \n",
    "    `Pb.names.txt`\n",
    "      \n",
    "    \n",
    "  * R script to run sleuth  \n",
    "    `sleuth.R`\n",
    "\n",
    "### Important questions\n",
    "\n",
    "**Can you summarise the experimental design?**\n",
    "\n",
    "The experimental design should explain what each sample represents, i.e. the conditions that were applied and how many replicates there were.  In this experiment, there are two conditions, wild type (WT) and knock out (KO), each of which has three biological replicates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Sample name | Condition | Replicate |\n",
    "| :-: | :-: | :-: |\n",
    "| WT | wild type | 1 |\n",
    "| WT | wild type | 2 |\n",
    "| WT | wild type | 3 |\n",
    "| KO | knock out | 1 |\n",
    "| KO | knock out | 2 |\n",
    "| KO | knock out | 3 |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning sample reads to the genome\n",
    "\n",
    "**First, we need to move into the directory containing the data.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/manager/course_data/group_projects/RNASeq_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Then,we build our HISAT2 index for the genome.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Settings:\n",
      "  Output files: \"PbANKA_v3_hisat2.idx.*.ht2\"\n",
      "  Line rate: 6 (line is 64 bytes)\n",
      "  Lines per side: 1 (side is 64 bytes)\n",
      "  Offset rate: 4 (one in 16)\n",
      "  FTable chars: 10\n",
      "  Strings: unpacked\n",
      "  Local offset rate: 3 (one in 8)\n",
      "  Local fTable chars: 6\n",
      "  Local sequence length: 57344\n",
      "  Local sequence overlap between two consecutive indexes: 1024\n",
      "  Endianness: little\n",
      "  Actual local endianness: little\n",
      "  Sanity checking: disabled\n",
      "  Assertions: disabled\n",
      "  Random seed: 0\n",
      "  Sizeofs: void*:8, int:4, long:8, size_t:8\n",
      "Input files DNA, FASTA:\n",
      "  PbANKA_v3.fasta\n",
      "Reading reference sizes\n",
      "  Time reading reference sizes: 00:00:01\n",
      "Calculating joined length\n",
      "Writing header\n",
      "Reserving space for joined string\n",
      "Joining reference sequences\n",
      "  Time to join reference sequences: 00:00:00\n",
      "  Time to read SNPs and splice sites: 00:00:00\n",
      "Using parameters --bmax 3521364 --dcv 1024\n",
      "  Doing ahead-of-time memory usage test\n",
      "  Passed!  Constructing with these parameters: --bmax 3521364 --dcv 1024\n",
      "Constructing suffix-array element generator\n",
      "Building DifferenceCoverSample\n",
      "  Building sPrime\n",
      "  Building sPrimeOrder\n",
      "  V-Sorting samples\n",
      "  V-Sorting samples time: 00:00:01\n",
      "  Allocating rank array\n",
      "  Ranking v-sort output\n",
      "  Ranking v-sort output time: 00:00:01\n",
      "  Invoking Larsson-Sadakane on ranks\n",
      "  Invoking Larsson-Sadakane on ranks time: 00:00:00\n",
      "  Sanity-checking and returning\n",
      "Building samples\n",
      "Reserving space for 12 sample suffixes\n",
      "Generating random suffixes\n",
      "QSorting 12 sample offsets, eliminating duplicates\n",
      "QSorting sample offsets, eliminating duplicates time: 00:00:00\n",
      "Multikey QSorting 12 samples\n",
      "  (Using difference cover)\n",
      "  Multikey QSorting samples time: 00:00:00\n",
      "Calculating bucket sizes\n",
      "Splitting and merging\n",
      "  Splitting and merging time: 00:00:00\n",
      "Avg bucket size: 2.68294e+06 (target: 3521363)\n",
      "Converting suffix-array elements to index image\n",
      "Allocating ftab, absorbFtab\n",
      "Entering GFM loop\n",
      "Getting block 1 of 7\n",
      "  Reserving size (3521364) for bucket 1\n",
      "  Calculating Z arrays for bucket 1\n",
      "  Entering block accumulator loop for bucket 1:\n",
      "  bucket 1: 10%\n",
      "  bucket 1: 20%\n",
      "  bucket 1: 30%\n",
      "  bucket 1: 40%\n",
      "  bucket 1: 50%\n",
      "  bucket 1: 60%\n",
      "  bucket 1: 70%\n",
      "  bucket 1: 80%\n",
      "  bucket 1: 90%\n",
      "  bucket 1: 100%\n",
      "  Sorting block of length 2544472 for bucket 1\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:02\n",
      "Returning block of 2544473 for bucket 1\n",
      "Getting block 2 of 7\n",
      "  Reserving size (3521364) for bucket 2\n",
      "  Calculating Z arrays for bucket 2\n",
      "  Entering block accumulator loop for bucket 2:\n",
      "  bucket 2: 10%\n",
      "  bucket 2: 20%\n",
      "  bucket 2: 30%\n",
      "  bucket 2: 40%\n",
      "  bucket 2: 50%\n",
      "  bucket 2: 60%\n",
      "  bucket 2: 70%\n",
      "  bucket 2: 80%\n",
      "  bucket 2: 90%\n",
      "  bucket 2: 100%\n",
      "  Sorting block of length 2737886 for bucket 2\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:01\n",
      "Returning block of 2737887 for bucket 2\n",
      "Getting block 3 of 7\n",
      "  Reserving size (3521364) for bucket 3\n",
      "  Calculating Z arrays for bucket 3\n",
      "  Entering block accumulator loop for bucket 3:\n",
      "  bucket 3: 10%\n",
      "  bucket 3: 20%\n",
      "  bucket 3: 30%\n",
      "  bucket 3: 40%\n",
      "  bucket 3: 50%\n",
      "  bucket 3: 60%\n",
      "  bucket 3: 70%\n",
      "  bucket 3: 80%\n",
      "  bucket 3: 90%\n",
      "  bucket 3: 100%\n",
      "  Sorting block of length 2801204 for bucket 3\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:02\n",
      "Returning block of 2801205 for bucket 3\n",
      "Getting block 4 of 7\n",
      "  Reserving size (3521364) for bucket 4\n",
      "  Calculating Z arrays for bucket 4\n",
      "  Entering block accumulator loop for bucket 4:\n",
      "  bucket 4: 10%\n",
      "  bucket 4: 20%\n",
      "  bucket 4: 30%\n",
      "  bucket 4: 40%\n",
      "  bucket 4: 50%\n",
      "  bucket 4: 60%\n",
      "  bucket 4: 70%\n",
      "  bucket 4: 80%\n",
      "  bucket 4: 90%\n",
      "  bucket 4: 100%\n",
      "  Sorting block of length 3410892 for bucket 4\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:01\n",
      "Returning block of 3410893 for bucket 4\n",
      "Getting block 5 of 7\n",
      "  Reserving size (3521364) for bucket 5\n",
      "  Calculating Z arrays for bucket 5\n",
      "  Entering block accumulator loop for bucket 5:\n",
      "  bucket 5: 10%\n",
      "  bucket 5: 20%\n",
      "  bucket 5: 30%\n",
      "  bucket 5: 40%\n",
      "  bucket 5: 50%\n",
      "  bucket 5: 60%\n",
      "  bucket 5: 70%\n",
      "  bucket 5: 80%\n",
      "  bucket 5: 90%\n",
      "  bucket 5: 100%\n",
      "  Sorting block of length 3480559 for bucket 5\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:01\n",
      "Returning block of 3480560 for bucket 5\n",
      "Getting block 6 of 7\n",
      "  Reserving size (3521364) for bucket 6\n",
      "  Calculating Z arrays for bucket 6\n",
      "  Entering block accumulator loop for bucket 6:\n",
      "  bucket 6: 10%\n",
      "  bucket 6: 20%\n",
      "  bucket 6: 30%\n",
      "  bucket 6: 40%\n",
      "  bucket 6: 50%\n",
      "  bucket 6: 60%\n",
      "  bucket 6: 70%\n",
      "  bucket 6: 80%\n",
      "  bucket 6: 90%\n",
      "  bucket 6: 100%\n",
      "  Sorting block of length 2614755 for bucket 6\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:02\n",
      "Returning block of 2614756 for bucket 6\n",
      "Getting block 7 of 7\n",
      "  Reserving size (3521364) for bucket 7\n",
      "  Calculating Z arrays for bucket 7\n",
      "  Entering block accumulator loop for bucket 7:\n",
      "  bucket 7: 10%\n",
      "  bucket 7: 20%\n",
      "  bucket 7: 30%\n",
      "  bucket 7: 40%\n",
      "  bucket 7: 50%\n",
      "  bucket 7: 60%\n",
      "  bucket 7: 70%\n",
      "  bucket 7: 80%\n",
      "  bucket 7: 90%\n",
      "  bucket 7: 100%\n",
      "  Sorting block of length 1190832 for bucket 7\n",
      "  (Using difference cover)\n",
      "  Sorting block time: 00:00:01\n",
      "Returning block of 1190833 for bucket 7\n",
      "Exited GFM loop\n",
      "fchr[A]: 0\n",
      "fchr[C]: 7334345\n",
      "fchr[G]: 9407661\n",
      "fchr[T]: 11474055\n",
      "fchr[$]: 18780606\n",
      "Exiting GFM::buildToDisk()\n",
      "Returning from initFromVector\n",
      "Wrote 10455188 bytes to primary GFM file: PbANKA_v3_hisat2.idx.1.ht2\n",
      "Wrote 4695156 bytes to secondary GFM file: PbANKA_v3_hisat2.idx.2.ht2\n",
      "Re-opening _in1 and _in2 as input streams\n",
      "Returning from GFM constructor\n",
      "Returning from initFromVector\n",
      "Wrote 8334245 bytes to primary GFM file: PbANKA_v3_hisat2.idx.5.ht2\n",
      "Wrote 4779620 bytes to secondary GFM file: PbANKA_v3_hisat2.idx.6.ht2\n",
      "Re-opening _in5 and _in5 as input streams\n",
      "Returning from HierEbwt constructor\n",
      "Headers:\n",
      "    len: 18780606\n",
      "    gbwtLen: 18780607\n",
      "    nodes: 18780607\n",
      "    sz: 4695152\n",
      "    gbwtSz: 4695152\n",
      "    lineRate: 6\n",
      "    offRate: 4\n",
      "    offMask: 0xfffffff0\n",
      "    ftabChars: 10\n",
      "    eftabLen: 0\n",
      "    eftabSz: 0\n",
      "    ftabLen: 1048577\n",
      "    ftabSz: 4194308\n",
      "    offsLen: 1173788\n",
      "    offsSz: 4695152\n",
      "    lineSz: 64\n",
      "    sideSz: 64\n",
      "    sideGbwtSz: 48\n",
      "    sideGbwtLen: 192\n",
      "    numSides: 97816\n",
      "    numLines: 97816\n",
      "    gbwtTotLen: 6260224\n",
      "    gbwtTotSz: 6260224\n",
      "    reverse: 0\n",
      "    linearFM: Yes\n",
      "Total time for call to driver() for forward index: 00:00:31\n"
     ]
    }
   ],
   "source": [
    "hisat2-build PbANKA_v3.fasta PbANKA_v3_hisat2.idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Next, we can use a for loop to align all of our sample files to the genome.**  \n",
    "_Be patient, this will take a while!_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aligning sample...KO1\n",
      "2160158 reads; of these:\n",
      "  2160158 (100.00%) were paired; of these:\n",
      "    100329 (4.64%) aligned concordantly 0 times\n",
      "    1918950 (88.83%) aligned concordantly exactly 1 time\n",
      "    140879 (6.52%) aligned concordantly >1 times\n",
      "    ----\n",
      "    100329 pairs aligned concordantly 0 times; of these:\n",
      "      5843 (5.82%) aligned discordantly 1 time\n",
      "    ----\n",
      "    94486 pairs aligned 0 times concordantly or discordantly; of these:\n",
      "      188972 mates make up the pairs; of these:\n",
      "        123409 (65.31%) aligned 0 times\n",
      "        56566 (29.93%) aligned exactly 1 time\n",
      "        8997 (4.76%) aligned >1 times\n",
      "97.14% overall alignment rate\n",
      "Converting sample SAM to sorted BAM...KO1\n",
      "[bam_sort_core] merging from 1 files and 1 in-memory blocks...\n",
      "Indexing sample BAM...KO1\n",
      "Aligning sample...KO2\n",
      "2978598 reads; of these:\n",
      "  2978598 (100.00%) were paired; of these:\n",
      "    394393 (13.24%) aligned concordantly 0 times\n",
      "    2413270 (81.02%) aligned concordantly exactly 1 time\n",
      "    170935 (5.74%) aligned concordantly >1 times\n",
      "    ----\n",
      "    394393 pairs aligned concordantly 0 times; of these:\n",
      "      32567 (8.26%) aligned discordantly 1 time\n",
      "    ----\n",
      "    361826 pairs aligned 0 times concordantly or discordantly; of these:\n",
      "      723652 mates make up the pairs; of these:\n",
      "        662685 (91.58%) aligned 0 times\n",
      "        50580 (6.99%) aligned exactly 1 time\n",
      "        10387 (1.44%) aligned >1 times\n",
      "88.88% overall alignment rate\n",
      "Converting sample SAM to sorted BAM...KO2\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "Indexing sample BAM...KO2\n",
      "Aligning sample...KO3\n",
      "2369330 reads; of these:\n",
      "  2369330 (100.00%) were paired; of these:\n",
      "    113286 (4.78%) aligned concordantly 0 times\n",
      "    2102841 (88.75%) aligned concordantly exactly 1 time\n",
      "    153203 (6.47%) aligned concordantly >1 times\n",
      "    ----\n",
      "    113286 pairs aligned concordantly 0 times; of these:\n",
      "      8695 (7.68%) aligned discordantly 1 time\n",
      "    ----\n",
      "    104591 pairs aligned 0 times concordantly or discordantly; of these:\n",
      "      209182 mates make up the pairs; of these:\n",
      "        136703 (65.35%) aligned 0 times\n",
      "        62082 (29.68%) aligned exactly 1 time\n",
      "        10397 (4.97%) aligned >1 times\n",
      "97.12% overall alignment rate\n",
      "Converting sample SAM to sorted BAM...KO3\n",
      "[bam_sort_core] merging from 1 files and 1 in-memory blocks...\n",
      "Indexing sample BAM...KO3\n",
      "Aligning sample...WT1\n",
      "2159162 reads; of these:\n",
      "  2159162 (100.00%) were paired; of these:\n",
      "    89648 (4.15%) aligned concordantly 0 times\n",
      "    1943096 (89.99%) aligned concordantly exactly 1 time\n",
      "    126418 (5.85%) aligned concordantly >1 times\n",
      "    ----\n",
      "    89648 pairs aligned concordantly 0 times; of these:\n",
      "      6417 (7.16%) aligned discordantly 1 time\n",
      "    ----\n",
      "    83231 pairs aligned 0 times concordantly or discordantly; of these:\n",
      "      166462 mates make up the pairs; of these:\n",
      "        102377 (61.50%) aligned 0 times\n",
      "        56547 (33.97%) aligned exactly 1 time\n",
      "        7538 (4.53%) aligned >1 times\n",
      "97.63% overall alignment rate\n",
      "Converting sample SAM to sorted BAM...WT1\n",
      "[bam_sort_core] merging from 1 files and 1 in-memory blocks...\n",
      "Indexing sample BAM...WT1\n",
      "Aligning sample...WT2\n",
      "3268692 reads; of these:\n",
      "  3268692 (100.00%) were paired; of these:\n",
      "    593095 (18.14%) aligned concordantly 0 times\n",
      "    2528063 (77.34%) aligned concordantly exactly 1 time\n",
      "    147534 (4.51%) aligned concordantly >1 times\n",
      "    ----\n",
      "    593095 pairs aligned concordantly 0 times; of these:\n",
      "      25803 (4.35%) aligned discordantly 1 time\n",
      "    ----\n",
      "    567292 pairs aligned 0 times concordantly or discordantly; of these:\n",
      "      1134584 mates make up the pairs; of these:\n",
      "        1072202 (94.50%) aligned 0 times\n",
      "        54375 (4.79%) aligned exactly 1 time\n",
      "        8007 (0.71%) aligned >1 times\n",
      "83.60% overall alignment rate\n",
      "Converting sample SAM to sorted BAM...WT2\n",
      "[bam_sort_core] merging from 2 files and 1 in-memory blocks...\n",
      "Indexing sample BAM...WT2\n",
      "Aligning sample...WT3\n",
      "2464139 reads; of these:\n",
      "  2464139 (100.00%) were paired; of these:\n",
      "    105631 (4.29%) aligned concordantly 0 times\n",
      "    2214127 (89.85%) aligned concordantly exactly 1 time\n",
      "    144381 (5.86%) aligned concordantly >1 times\n",
      "    ----\n",
      "    105631 pairs aligned concordantly 0 times; of these:\n",
      "      11286 (10.68%) aligned discordantly 1 time\n",
      "    ----\n",
      "    94345 pairs aligned 0 times concordantly or discordantly; of these:\n",
      "      188690 mates make up the pairs; of these:\n",
      "        107077 (56.75%) aligned 0 times\n",
      "        72277 (38.30%) aligned exactly 1 time\n",
      "        9336 (4.95%) aligned >1 times\n",
      "97.83% overall alignment rate\n",
      "Converting sample SAM to sorted BAM...WT3\n",
      "[bam_sort_core] merging from 1 files and 1 in-memory blocks...\n",
      "Indexing sample BAM...WT3\n"
     ]
    }
   ],
   "source": [
    "for fname in *_1.fastq.gz\n",
    "do\n",
    "    # Get sample name from file name\n",
    "    sample=`echo \"$fname\" | cut -d'_' -f1`\n",
    "\n",
    "    # Align sample to genome\n",
    "    echo \"Aligning sample...\"${sample}\n",
    "    hisat2 --max-intronlen 10000 -x PbANKA_v3_hisat2.idx \\\n",
    "    -1 ${sample}_1.fastq.gz -2 ${sample}_2.fastq.gz \\\n",
    "    -S ${sample}.sam\n",
    "\n",
    "    # Convert SAM to sorted BAM\n",
    "    echo \"Converting sample SAM to sorted BAM...\"${sample}\n",
    "    samtools view -b ${sample}.sam | \\\n",
    "    samtools sort -o ${sample}.sorted.bam\n",
    "\n",
    "    # Index sorted BAM\n",
    "    echo \"Indexing sample BAM...\"${sample}\n",
    "    samtools index ${sample}.sorted.bam\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important questions\n",
    "\n",
    "**What is the overall alignment rate for each of the samples?**\n",
    "\n",
    "It is important to look at the overall alignment rate to the genome as this can give an idea of whether there are any issues with the experiment (e.g. contamination)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Sample name | Alignment rate|\n",
    "| :-: | :-: |\n",
    "| WT1 | 97.63% |\n",
    "| WT2 | 83.60% |\n",
    "| WT3 | 97.83% |\n",
    "| KO1 | 97.14% |\n",
    "| KO2 | 88.88% |\n",
    "| KO3 | 97.12% |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualising the genome alignments \n",
    "\n",
    "Before you can use IGV to visualise the genome, you must first index the genome using `samtools faidx`.\n",
    "\n",
    "**Index the genome.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "samtools faidx PbANKA_v3.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once that has finished, you need to load your genome (`PbANKA_v3.fasta`), annotation (`PbANKA_v3.gff3.gz`) and sorted alignment files (`[sample].sorted.bam`) into IGV.\n",
    "\n",
    "**Start IGV.**  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] 22359\n"
     ]
    }
   ],
   "source": [
    "igv.sh &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load the genome file `Genomes -> Load Genome from File`**  \n",
    "\n",
    "**Load the annotation (gff) file `File -> Load from File`**   \n",
    "\n",
    "**Load the sorted sample BAM files `File -> Load from File`** \n",
    "\n",
    "**Make sure to set the alignment tracks to \"squished\" and to view reads as \"paired\".**\n",
    "\n",
    "**Type 'PBANKA_KO' in the search box and click 'Go'.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![images/PBANKA_KO_IGV.png](images/PBANKA_KO_IGV.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important questions\n",
    "\n",
    "**Where in the genome is PBANKA_KO located?**\n",
    "\n",
    "You can get the co-ordinates of PBANKA_KO from the annotation file (`PbANKA_v3.gff3.gz`) using `grep` (first uncompressing the file with `gunzip`) or `zgrep`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PbANKA_14_v3\tchado\tgene\t1416412\t1423431\t.\t+\t.\tID=PBANKA_KO;Name=PBANKA_KO\n",
      "PbANKA_14_v3\tchado\tmRNA\t1416412\t1423431\t.\t+\t.\tID=PBANKA_KO.1;Parent=PBANKA_KO\n",
      "PbANKA_14_v3\tchado\tCDS\t1416412\t1423431\t.\t+\t0\tID=PBANKA_KO.1:exon:1;Parent=PBANKA_KO.1\n",
      "PbANKA_14_v3    chado   polypeptide     1416412 1423431 .       +       .       ID=PBANKA_KO.1:pep;Dbxref=RMgm:PBANKA_KO;Derives_from=PBANKA_KO.1\n"
     ]
    }
   ],
   "source": [
    "zgrep PBANKA_KO PbANKA_v3.gff3.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PBANKA_KO is located on the forward strand of **PbANKA_14_v3** between **1416412** and **1423431**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**How many exons does PBANKA_KO have?**\n",
    "\n",
    "In IGV, you can see that PBANKA_KO has **one exon**.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![images/PBANKA_KO_IGV_exon.png](images/PBANKA_KO_IGV_exon.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This can be confirmed by looking for the PBANKA_KO CDS annotations the GFF file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PbANKA_14_v3\tchado\tCDS\t1416412\t1423431\t.\t+\t0\tID=PBANKA_KO.1:exon:1;Parent=PBANKA_KO.1\n"
     ]
    }
   ],
   "source": [
    "zgrep CDS.*PBANKA_KO PbANKA_v3.gff3.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do you notice anything unusual about any of the alignments to PBANKA_KO? Should there be any reads mapping to this knocked out gene?**\n",
    "\n",
    "Reads are mapping to PBANKA_KO for the KO3 sample.  Suggests this may be an incomplete knock out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![images/PBANKA_KO_IGV_coverage.png](images/PBANKA_KO_IGV_coverage.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aligning sample reads to the transcriptome\n",
    "\n",
    "**First we need to build a Kallisto index of our tanscriptome (`Pb.CDS.fasta`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO [2018-12-06 09:39:22,377]  [IGV.java:1700] [pool-1-thread-1]  Loading 3 resources.\n",
      "INFO [2018-12-06 09:39:22,377]  [TrackLoader.java:120] [pool-1-thread-1]  Loading resource, path /home/manager/course_data/group_projects/RNASeq_1/WT1.sorted.bam\n",
      "INFO [2018-12-06 09:39:22,454]  [TrackLoader.java:120] [pool-1-thread-1]  Loading resource, path /home/manager/course_data/group_projects/RNASeq_1/WT2.sorted.bam\n",
      "INFO [2018-12-06 09:39:22,599]  [TrackLoader.java:120] [pool-1-thread-1]  Loading resource, path /home/manager/course_data/group_projects/RNASeq_1/WT3.sorted.bam\n",
      "INFO [2018-12-06 09:41:28,638]  [IGV.java:1700] [pool-1-thread-1]  Loading 6 resources.\n",
      "INFO [2018-12-06 09:41:28,640]  [TrackLoader.java:120] [pool-1-thread-1]  Loading resource, path /home/manager/course_data/group_projects/RNASeq_1/KO1.sorted.bam\n",
      "INFO [2018-12-06 09:41:28,649]  [TrackLoader.java:120] [pool-1-thread-1]  Loading resource, path /home/manager/course_data/group_projects/RNASeq_1/KO2.sorted.bam\n",
      "INFO [2018-12-06 09:41:28,749]  [TrackLoader.java:120] [pool-1-thread-1]  Loading resource, path /home/manager/course_data/group_projects/RNASeq_1/KO3.sorted.bam\n",
      "INFO [2018-12-06 09:41:28,817]  [TrackLoader.java:120] [pool-1-thread-1]  Loading resource, path /home/manager/course_data/group_projects/RNASeq_1/WT1.sorted.bam\n",
      "INFO [2018-12-06 09:41:28,905]  [TrackLoader.java:120] [pool-1-thread-1]  Loading resource, path /home/manager/course_data/group_projects/RNASeq_1/WT2.sorted.bam\n",
      "INFO [2018-12-06 09:41:29,049]  [TrackLoader.java:120] [pool-1-thread-1]  Loading resource, path /home/manager/course_data/group_projects/RNASeq_1/WT3.sorted.bam\n",
      "\n",
      "[build] loading fasta file Pb.CDS.fasta\n",
      "[build] k-mer length: 31\n",
      "[build] counting k-mers ... done.\n",
      "[build] building target de Bruijn graph ...  done \n",
      "[build] creating equivalence classes ...  done\n",
      "[build] target de Bruijn graph has 13763 contigs and contains 9949889 k-mers \n",
      "\n"
     ]
    }
   ],
   "source": [
    "kallisto index -i Pb.CDS.kallisto Pb.CDS.fasta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As with the genome alignments, we can run the transcriptome alignments for all the samples using a loop.\n",
    "\n",
    "**Now, align your samples to the transcriptome using Kallisto.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kallisto quantification for sample...KO1\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 5,077\n",
      "[index] number of k-mers: 9,949,889\n",
      "[index] number of equivalence classes: 7,297\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: KO1_1.fastq.gz\n",
      "                             KO1_2.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 2,160,158 reads, 1,760,542 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 270.873\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 286 rounds\n",
      "[bstrp] running EM for the bootstrap: 100\n",
      "\n",
      "kallisto quantification for sample...KO2\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 5,077\n",
      "[index] number of k-mers: 9,949,889\n",
      "[index] number of equivalence classes: 7,297\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: KO2_1.fastq.gz\n",
      "                             KO2_2.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 2,978,598 reads, 2,314,533 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 238.403\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 647 rounds\n",
      "[bstrp] running EM for the bootstrap: 100\n",
      "\n",
      "kallisto quantification for sample...KO3\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 5,077\n",
      "[index] number of k-mers: 9,949,889\n",
      "[index] number of equivalence classes: 7,297\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: KO3_1.fastq.gz\n",
      "                             KO3_2.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 2,369,330 reads, 1,984,136 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 279.705\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 359 rounds\n",
      "[bstrp] running EM for the bootstrap: 100\n",
      "\n",
      "kallisto quantification for sample...WT1\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 5,077\n",
      "[index] number of k-mers: 9,949,889\n",
      "[index] number of equivalence classes: 7,297\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: WT1_1.fastq.gz\n",
      "                             WT1_2.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 2,159,162 reads, 1,810,848 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 280.722\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 313 rounds\n",
      "[bstrp] running EM for the bootstrap: 100\n",
      "\n",
      "kallisto quantification for sample...WT2\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 5,077\n",
      "[index] number of k-mers: 9,949,889\n",
      "[index] number of equivalence classes: 7,297\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: WT2_1.fastq.gz\n",
      "                             WT2_2.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 3,268,692 reads, 2,450,275 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 273.089\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 697 rounds\n",
      "[bstrp] running EM for the bootstrap: 100\n",
      "\n",
      "kallisto quantification for sample...WT3\n",
      "\n",
      "[quant] fragment length distribution will be estimated from the data\n",
      "[index] k-mer length: 31\n",
      "[index] number of targets: 5,077\n",
      "[index] number of k-mers: 9,949,889\n",
      "[index] number of equivalence classes: 7,297\n",
      "[quant] running in paired-end mode\n",
      "[quant] will process pair 1: WT3_1.fastq.gz\n",
      "                             WT3_2.fastq.gz\n",
      "[quant] finding pseudoalignments for the reads ... done\n",
      "[quant] processed 2,464,139 reads, 2,097,576 reads pseudoaligned\n",
      "[quant] estimated average fragment length: 295.093\n",
      "[   em] quantifying the abundances ... done\n",
      "[   em] the Expectation-Maximization algorithm ran for 381 rounds\n",
      "[bstrp] running EM for the bootstrap: 100\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for fname in *_1.fastq.gz\n",
    "do\n",
    "    # Get sample name from file name\n",
    "    sample=`echo \"$fname\" | cut -d'_' -f1`\n",
    "    \n",
    "    # Quantify transcript expression in sample\n",
    "    echo \"kallisto quantification for sample...\"${sample}\n",
    "    kallisto quant -i Pb.CDS.kallisto -o ${sample} -b 100 \\\n",
    "    ${sample}_1.fastq.gz ${sample}_2.fastq.gz\n",
    "done"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run DE analysis in sleuth\n",
    "\n",
    "To identify differentially expressed genes you can use the R package, sleuth.  \n",
    "\n",
    "**Run the sleuth R script (`sleuth.R`).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading required package: methods\n",
      "There were 15 warnings (use warnings() to see them)\n",
      "Error in file(file, \"rt\") : cannot open the connection\n",
      "Calls: read.table -> file\n",
      "In addition: Warning message:\n",
      "In file(file, \"rt\") :\n",
      "  cannot open file 'hiseq_info.txt': No such file or directory\n",
      "Execution halted\n"
     ]
    },
    {
     "ename": "",
     "evalue": "1",
     "output_type": "error",
     "traceback": []
    }
   ],
   "source": [
    "Rscript sleuth.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This will give you the error:\n",
    "\n",
    "    cannot open file 'hiseq_info.txt': No such file or directory\n",
    "    \n",
    "**Take a look at the R script.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "library(\"sleuth\")\n",
      "s2c <- read.table(\"hiseq_info.txt\", header = TRUE, stringsAsFactors=FALSE)\n",
      "\n",
      "sample_id <- c(\"WT1\", \"WT2\",\"WT3\", \"KO1\", \"KO2\", \"KO3\")\n",
      "kal_dirs <- sapply(sample_id, function(id) file.path(\".\", id))\n",
      "s2c <- dplyr::select(s2c, sample = sample, condition)\n",
      "s2c <- dplyr::mutate(s2c, path = kal_dirs)\n",
      "\n",
      "t2g<-read.table(\"Pb.names.txt\", header=T, sep=\"\\t\")\n",
      "\n",
      "so <- sleuth_prep(s2c, ~ condition, target_mapping = t2g)\n",
      "so <- sleuth_fit(so)\n",
      "so <- sleuth_fit(so, ~1, 'reduced')\n",
      "#so <- sleuth_lrt(so, 'reduced', 'full')\n",
      "so <- sleuth_wt(so, 'conditionWT', 'full')\n",
      "\n",
      "results_table <- sleuth_results(so, 'conditionWT', test_type = 'wt')\n",
      "\n",
      "write.table(results_table, file=\"kallisto.results\", quote=FALSE, sep=\"\\t\", row.names=FALSE)\n",
      "\n",
      "sleuth_live(so)\n"
     ]
    }
   ],
   "source": [
    "cat sleuth.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the second line:\n",
    "\n",
    "    s2c <- read.table(\"hiseq_info.txt\", header = TRUE, stringsAsFactors=FALSE)\n",
    "    \n",
    "The script is looking for a file called `hiseq_info.txt`.  \n",
    "\n",
    "**Let's see if the file is there.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hiseq_info.txt\n"
     ]
    }
   ],
   "source": [
    "ls hiseq_info.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nope.  Well...we did warn you that some files might be missing!\n",
    "\n",
    "**What does the `hiseq_info.txt` file contain? Let's look at the one we used in the practical.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample\tcondition\n",
      "MT1\tMT\n",
      "MT2\tMT\n",
      "SBP1\tSBP\n",
      "SBP2\tSBP\n",
      "SBP3\tSBP\n"
     ]
    }
   ],
   "source": [
    "cat /home/manager/pathogen-informatics-training/Notebooks/RNA-Seq/data/hiseq_info.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, this file shows which condition was applied to each sample.\n",
    "\n",
    "**Copy this file into the same directory as your sleuth R script.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "cp /home/manager/pathogen-informatics-training/Notebooks/RNA-Seq/data/hiseq_info.txt ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's check that worked.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample\tcondition\n",
      "MT1\tMT\n",
      "MT2\tMT\n",
      "SBP1\tSBP\n",
      "SBP2\tSBP\n",
      "SBP3\tSBP\n"
     ]
    }
   ],
   "source": [
    "cat hiseq_info.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good, now let's update this file so it contains our sample names.\n",
    "\n",
    "**You can edit the file manually by typing the following `nano` command in your terminal.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/manager/course_data/group_projects/RNASeq_1\n"
     ]
    }
   ],
   "source": [
    "nano /home/manager/course_data/group_projects/RNASeq_1/hiseq_info.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Hint: be careful which order you put the samples in._\n",
    "\n",
    "**Alternatively you can make the edits using `sed`.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sed -i -e 's/MT/WT/g' hiseq_info.txt\n",
    "sed -i -e 's/SBP/KO/g' hiseq_info.txt\n",
    "sed -ie '/^WT2/a WT3\\tWT' hiseq_info.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**And check that it's worked.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample\tcondition\n",
      "WT1\tWT\n",
      "WT2\tWT\n",
      "WT3\tWT\n",
      "KO1\tKO\n",
      "KO2\tKO\n",
      "KO3\tKO\n"
     ]
    }
   ],
   "source": [
    "cat hiseq_info.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Now try running the sleuth R script again.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading required package: methods\n",
      "There were 15 warnings (use warnings() to see them)\n",
      "reading in kallisto results\n",
      "dropping unused factor levels\n",
      "......\n",
      "normalizing est_counts\n",
      "4811 targets passed the filter\n",
      "normalizing tpm\n",
      "merging in metadata\n",
      "summarizing bootstraps\n",
      "......\n",
      "fitting measurement error models\n",
      "shrinkage estimation\n",
      "11 NA values were found during variance shrinkage estimation due to mean observation values outside of the range used for the LOESS fit.\n",
      "The LOESS fit will be repeated using exact computation of the fitted surface to extrapolate the missing values.\n",
      "These are the target ids with NA values: PBANKA_0000301, PBANKA_0001101, PBANKA_0700541, PBANKA_1040521, PBANKA_1241400, PBANKA_1418000, PBANKA_1465700, PBANKA_API00390, PBANKA_0707700, PBANKA_0941800, PBANKA_1122700\n",
      "computing variance of betas\n",
      "fitting measurement error models\n",
      "shrinkage estimation\n",
      "2 NA values were found during variance shrinkage estimation due to mean observation values outside of the range used for the LOESS fit.\n",
      "The LOESS fit will be repeated using exact computation of the fitted surface to extrapolate the missing values.\n",
      "These are the target ids with NA values: PBANKA_0941800, PBANKA_1122700\n",
      "computing variance of betas\n",
      "Loading required package: shiny\n",
      "\n",
      "Listening on http://127.0.0.1:42427\n",
      "Warning in seq_len(nrow(layout)) :\n",
      "  first element used of 'length.out' argument\n",
      "Warning: Error in transcripts_from_gene: Couldn't find gene PBANKA_KO\n",
      "Stack trace (innermost first):\n",
      "    116: transcripts_from_gene\n",
      "    115: <reactive>\n",
      "    104: gv_var_list\n",
      "    103: renderPlot\n",
      "     93: <reactive:plotObj>\n",
      "     82: plotObj\n",
      "     81: origRenderFunc\n",
      "     80: output$plot3\n",
      "      4: <Anonymous>\n",
      "      3: do.call\n",
      "      2: print.shiny.appobj\n",
      "      1: <Promise>\n",
      "Warning: Error in transcripts_from_gene: Couldn't find gene PBANKA_KO\n",
      "Stack trace (innermost first):\n",
      "    106: <Anonymous>\n",
      "    105: stop\n",
      "    104: gv_var_list\n",
      "    103: renderPlot\n",
      "     93: <reactive:plotObj>\n",
      "     82: plotObj\n",
      "     81: origRenderFunc\n",
      "     80: output$plot1\n",
      "      4: <Anonymous>\n",
      "      3: do.call\n",
      "      2: print.shiny.appobj\n",
      "      1: <Promise>\n",
      "Warning: Error in transcripts_from_gene: Couldn't find gene PBANKA_KO\n",
      "Stack trace (innermost first):\n",
      "    106: <Anonymous>\n",
      "    105: stop\n",
      "    104: gv_var_list\n",
      "    103: renderPlot\n",
      "     93: <reactive:plotObj>\n",
      "     82: plotObj\n",
      "     81: origRenderFunc\n",
      "     80: output$plot2\n",
      "      4: <Anonymous>\n",
      "      3: do.call\n",
      "      2: print.shiny.appobj\n",
      "      1: <Promise>\n",
      "Warning in seq_len(nrow(layout)) :\n",
      "  first element used of 'length.out' argument\n",
      "Warning in seq_len(nrow(layout)) :\n",
      "  first element used of 'length.out' argument\n",
      "Warning in seq_len(nrow(layout)) :\n",
      "  first element used of 'length.out' argument\n",
      "Warning in seq_len(nrow(layout)) :\n",
      "  first element used of 'length.out' argument\n",
      "\n",
      "Warning message:\n",
      "replacing previous import by ‘Rcpp::evalCpp’ when loading ‘later’ \n",
      "\n",
      "Execution halted\n"
     ]
    }
   ],
   "source": [
    "Rscript sleuth.R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Click on the link returned: [http://127.0.0.1:42427](http://127.0.0.1:42427).**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important questions\n",
    "\n",
    "Can you summarise how the data processing (i.e. number of reads processed and the proportion of reads mapping to the genome and transcriptome)? \n",
    "\n",
    "Looking at the PCA plot (`Maps -> PCA`) do you think the samples form tight, distinct clusters based on the condition (WT or KO) that was applied? \n",
    "\n",
    "Was PBANKA_KO differentially expressed? \n",
    "\n",
    "Is there anything unusual about the PBANKA_KO expression levels in any of the samples?\n",
    "\n",
    "How many genes are more highly expressed in the KO than in the WT?\n",
    "\n",
    "How many genes are more highly expressed in the WT than in the KO?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GO term enrichment analysis\n",
    "\n",
    "\n",
    "Extract the IDs of the differentially expressed genes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/manager/course_data/group_projects/RNASeq_1\n",
    "awk -F'\\t' '$4 < 0.01 && $5 > 0  {print $1}' kallisto.results > kallisto.WT.sig.genes\n",
    "awk -F'\\t' '$4 < 0.01 && $5 < 0  {print $1}' kallisto.results > kallisto.KO.sig.genes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Go to [http://www.plasmodb.org](http://www.plasmodb.org).\n",
    "\n",
    "My Strategies -> New\n",
    "Annotation, curation and identifiers -> Gene IDs\n",
    "Upload file of DE gene IDs from kallisto output\n",
    "Analyse results (blue button) -> GO enrichment\n",
    "\n",
    "\n",
    "### Important questions\n",
    "\n",
    "What are the top 5 enriched GO terms (biological processes and molecular functions) of genes with higher expression in the WT samples?\n",
    "What are the top 5 enriched GO terms (biological processes and molecular functions) of genes with higher expression in the KO samples?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is PBANKA_KO?\n",
    "\n",
    "So, for this group task, we removed the real name of PBANKA_KO from all of the files we gave you. How mean! To get the real name of PBANKA_KO, we need the real genome annotation file.\n",
    "\n",
    "**Download the real annotation file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2018-12-06 12:08:20--  ftp://ftp.sanger.ac.uk/pub/project/pathogens/gff3/CURRENT/Pberghei.gff3.gz\n",
      "           => ‘Pberghei.gff3.gz’\n",
      "Resolving ftp.sanger.ac.uk (ftp.sanger.ac.uk)... 193.62.203.115\n",
      "Connecting to ftp.sanger.ac.uk (ftp.sanger.ac.uk)|193.62.203.115|:21... connected.\n",
      "Logging in as anonymous ... Logged in!\n",
      "==> SYST ... done.    ==> PWD ... done.\n",
      "==> TYPE I ... done.  ==> CWD (1) /pub/project/pathogens/gff3/CURRENT ... done.\n",
      "==> SIZE Pberghei.gff3.gz ... 9151369\n",
      "==> PASV ... done.    ==> RETR Pberghei.gff3.gz ... done.\n",
      "Length: 9151369 (8.7M) (unauthoritative)\n",
      "\n",
      "100%[======================================>] 9,151,369   12.8MB/s   in 0.7s   \n",
      "\n",
      "2018-12-06 12:08:21 (12.8 MB/s) - ‘Pberghei.gff3.gz’ saved [9151369]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "wget ftp://ftp.sanger.ac.uk/pub/project/pathogens/gff3/CURRENT/Pberghei.gff3.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, earlier on, you will have jotted down the location of PBANKA_KO in the genome.\n",
    "\n",
    "**Search for a gene with the same co-ordinates as PBANKA_KO in the reall annotation file.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PbANKA_14_v3\tchado\tgene\t1416412\t1423431\t.\t+\t.\tID=PBANKA_1437500;Name=AP2-G;previous_systematic_id=PB000234.02.0,PBANKA_143750;synonym=ApiAP2\n"
     ]
    }
   ],
   "source": [
    "zgrep \"PbANKA_14_v3.*gene.*1416412.*1423431\" Pberghei.gff3.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like PBANKA_KO is really **PBANKA_1437500**, better known as **AP2-G**, in disguise!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Bash",
   "language": "bash",
   "name": "bash"
  },
  "language_info": {
   "codemirror_mode": "shell",
   "file_extension": ".sh",
   "mimetype": "text/x-sh",
   "name": "bash"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
